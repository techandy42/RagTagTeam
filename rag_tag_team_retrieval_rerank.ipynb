{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOZxpvX7ASJkap+4eAggnCk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techandy42/RagTagTeam/blob/main/rag_tag_team_retrieval_rerank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRWuGC4vYfP6"
      },
      "outputs": [],
      "source": [
        "COHERE_API_KEY = \"LFwtrOMC4TCNjslyIJG6f7vGAENVzC7mwT8NXo8r\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere hnswlib unstructured -q"
      ],
      "metadata": {
        "id": "50Z4_YLAoPa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r profiles profiles.zip"
      ],
      "metadata": {
        "id": "tyRVSLlnIgPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "euQ3aNHo6mu2",
        "outputId": "18c6516a-abac-4886-dbcb-420392b240c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dafa7c2d-cff7-491f-ab72-01e0b975e330\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dafa7c2d-cff7-491f-ab72-01e0b975e330\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving profiles.zip to profiles.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip profiles.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EcuJnOs6xdU",
        "outputId": "62a3cdd8-a6f5-44c1-ca7b-51c291f11ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  profiles.zip\n",
            "   creating: profiles/\n",
            "  inflating: profiles/arts1.json     \n",
            "  inflating: profiles/arts2.json     \n",
            "  inflating: profiles/arts3.json     \n",
            "  inflating: profiles/arts4.json     \n",
            "  inflating: profiles/arts5.json     \n",
            "  inflating: profiles/backend1.json  \n",
            "  inflating: profiles/backend2.json  \n",
            "  inflating: profiles/backend3.json  \n",
            "  inflating: profiles/backend4.json  \n",
            "  inflating: profiles/backend5.json  \n",
            "  inflating: profiles/business1.json  \n",
            "  inflating: profiles/business2.json  \n",
            "  inflating: profiles/business3.json  \n",
            "  inflating: profiles/business4.json  \n",
            "  inflating: profiles/business5.json  \n",
            "  inflating: profiles/c_suite1.json  \n",
            "  inflating: profiles/c_suite2.json  \n",
            "  inflating: profiles/c_suite3.json  \n",
            "  inflating: profiles/c_suite4.json  \n",
            "  inflating: profiles/c_suite5.json  \n",
            "  inflating: profiles/finance1.json  \n",
            "  inflating: profiles/finance2.json  \n",
            "  inflating: profiles/finance3.json  \n",
            "  inflating: profiles/finance4.json  \n",
            "  inflating: profiles/finance5.json  \n",
            "  inflating: profiles/frontend1.json  \n",
            "  inflating: profiles/frontend2.json  \n",
            "  inflating: profiles/frontend3.json  \n",
            "  inflating: profiles/frontend4.json  \n",
            "  inflating: profiles/frontend5.json  \n",
            "  inflating: profiles/journalist1.json  \n",
            "  inflating: profiles/journalist2.json  \n",
            "  inflating: profiles/journalist3.json  \n",
            "  inflating: profiles/journalist4.json  \n",
            "  inflating: profiles/journalist5.json  \n",
            "  inflating: profiles/manager1.json  \n",
            "  inflating: profiles/manager2.json  \n",
            "  inflating: profiles/manager3.json  \n",
            "  inflating: profiles/manager4.json  \n",
            "  inflating: profiles/manager5.json  \n",
            "  inflating: profiles/medical1.json  \n",
            "  inflating: profiles/medical2.json  \n",
            "  inflating: profiles/medical3.json  \n",
            "  inflating: profiles/medical4.json  \n",
            "  inflating: profiles/medical5.json  \n",
            "  inflating: profiles/ml_ds1.json    \n",
            "  inflating: profiles/ml_ds2.json    \n",
            "  inflating: profiles/ml_ds3.json    \n",
            "  inflating: profiles/ml_ds4.json    \n",
            "  inflating: profiles/ml_ds5.json    \n",
            "  inflating: profiles/startup1.json  \n",
            "  inflating: profiles/startup10.json  \n",
            "  inflating: profiles/startup11.json  \n",
            "  inflating: profiles/startup12.json  \n",
            "  inflating: profiles/startup13.json  \n",
            "  inflating: profiles/startup14.json  \n",
            "  inflating: profiles/startup15.json  \n",
            "  inflating: profiles/startup16.json  \n",
            "  inflating: profiles/startup17.json  \n",
            "  inflating: profiles/startup18.json  \n",
            "  inflating: profiles/startup19.json  \n",
            "  inflating: profiles/startup2.json  \n",
            "  inflating: profiles/startup20.json  \n",
            "  inflating: profiles/startup21.json  \n",
            "  inflating: profiles/startup22.json  \n",
            "  inflating: profiles/startup23.json  \n",
            "  inflating: profiles/startup24.json  \n",
            "  inflating: profiles/startup25.json  \n",
            "  inflating: profiles/startup3.json  \n",
            "  inflating: profiles/startup4.json  \n",
            "  inflating: profiles/startup5.json  \n",
            "  inflating: profiles/startup6.json  \n",
            "  inflating: profiles/startup7.json  \n",
            "  inflating: profiles/startup8.json  \n",
            "  inflating: profiles/startup9.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "import os\n",
        "import hnswlib\n",
        "import json\n",
        "import uuid\n",
        "from typing import List, Dict\n",
        "from unstructured.partition.html import partition_html\n",
        "from unstructured.chunking.title import chunk_by_title\n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "co = cohere.Client(COHERE_API_KEY)"
      ],
      "metadata": {
        "id": "sr69cS4XoQ7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def read_json_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "def json_files_to_list_of_dicts(directory_path):\n",
        "    data_list = []\n",
        "\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith('.json'):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            json_data = read_json_file(file_path)\n",
        "            data_list.append(json_data)\n",
        "\n",
        "    return data_list\n",
        "\n",
        "directory_path = 'profiles'\n",
        "profiles = json_files_to_list_of_dicts(directory_path)\n",
        "\n",
        "print(len(profiles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU3G4BDB61x0",
        "outputId": "315595f7-8a52-431f-eebf-19ce10ef7fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(dict):\n",
        "    # Take in a dict and convert it to a string with an associated user id\n",
        "    experiences = \"\"\n",
        "    for experience in dict[\"experience\"]:\n",
        "        responsibilities = \"\"\n",
        "        for responsibility in experience[\"responsibilities\"]:\n",
        "          responsibilities = responsibilities +  responsibility  + \"\\n\"\n",
        "        experiences += (\n",
        "            f\"Position: {experience['position']}\\n\"\n",
        "            f\"Duration: {experience['duration']}\\n\"\n",
        "            f\"Location: {experience['location']}\\n\"\n",
        "            f\"Responsibilities: {responsibilities}\\n\"\n",
        "        )\n",
        "    skills = \"\"\n",
        "    for skill in dict[\"skills\"]:\n",
        "        skills += f\"{skill}\\n\"\n",
        "\n",
        "    educations = \"\"\n",
        "    for education in dict[\"education\"]:\n",
        "        educations += (\n",
        "            f\"Degree: {education['degree']}\\n\"\n",
        "            f\"University: {education['university']}\\n\"\n",
        "            f\"Location: {education['location']}\\n\"\n",
        "            f\"Graduation Year: {education['graduation_year']}\\n\"\n",
        "        )\n",
        "\n",
        "    linkedinstring = (\n",
        "        f\"Background: {dict['background']}\\n\"\n",
        "        f\"Experiences: {experiences}\\n\"\n",
        "        f\"Education: {educations}\\n\"\n",
        "        f\"Skills: {skills}\\n\"\n",
        "    )\n",
        "    return linkedinstring"
      ],
      "metadata": {
        "id": "EpmAFjwRNejX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Documents:\n",
        "  def __init__(self, sources: List[Dict[str, str]]):\n",
        "    self.sources = sources\n",
        "    self.docs = []\n",
        "    self.docs_embs = []\n",
        "    self.retrieve_top_k = 20\n",
        "    self.rerank_top_k = 5\n",
        "    self.load()\n",
        "    self.embed()\n",
        "    self.index()\n",
        "\n",
        "  def load(self) -> None:\n",
        "    for index, source in enumerate(self.sources):\n",
        "      self.docs.append({'text': preprocess(source), 'id': index})\n",
        "\n",
        "  def embed(self) -> None:\n",
        "    \"\"\"\n",
        "    Embeds the documents using the Cohere API.\n",
        "    \"\"\"\n",
        "    print(\"Embedding documents...\")\n",
        "\n",
        "    batch_size = 90\n",
        "    self.docs_len = len(self.docs)\n",
        "\n",
        "    for i in range(0, self.docs_len, batch_size):\n",
        "      batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
        "      texts = [item['text'] for item in batch]\n",
        "      docs_embs_batch = co.embed(\n",
        "        texts=texts,\n",
        "        model=\"embed-english-v3.0\",\n",
        "        input_type=\"search_document\"\n",
        "\t \t\t).embeddings\n",
        "      self.docs_embs.extend(docs_embs_batch)\n",
        "\n",
        "  def index(self) -> None:\n",
        "    \"\"\"\n",
        "    Indexes the documents for efficient retrieval.\n",
        "    \"\"\"\n",
        "    print(\"Indexing documents...\")\n",
        "\n",
        "    self.index = hnswlib.Index(space=\"ip\", dim=1024)\n",
        "    self.index.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
        "    self.index.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
        "\n",
        "    print(f\"Indexing complete with {self.index.get_current_count()} documents.\")\n",
        "\n",
        "  def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Retrieves documents based on the given query.\n",
        "\n",
        "    Parameters:\n",
        "    query (str): The query to retrieve documents for.\n",
        "\n",
        "    Returns:\n",
        "    List[Dict[str, str]]: A list of dictionaries representing the retrieved  documents, with 'title', 'snippet', and 'url' keys.\n",
        "    \"\"\"\n",
        "    docs_retrieved = []\n",
        "    query_emb = co.embed(\n",
        "      texts=[query],\n",
        "      model=\"embed-english-v3.0\",\n",
        "      input_type=\"search_query\"\n",
        "    ).embeddings\n",
        "\n",
        "    doc_ids = self.index.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
        "\n",
        "    docs_to_rerank = []\n",
        "    for doc_id in doc_ids:\n",
        "        docs_to_rerank.append(self.docs[doc_id])\n",
        "\n",
        "    rerank_results = co.rerank(\n",
        "        query=query,\n",
        "        documents=docs_to_rerank,\n",
        "        top_n=self.rerank_top_k,\n",
        "        model=\"rerank-english-v2.0\",\n",
        "    )\n",
        "\n",
        "    doc_ids_reranked = []\n",
        "    for result in rerank_results:\n",
        "        doc_ids_reranked.append(doc_ids[result.index])\n",
        "\n",
        "    for doc_id in doc_ids_reranked:\n",
        "        docs_retrieved.append(\n",
        "            {\n",
        "                \"text\": self.docs[doc_id]['text'],\n",
        "                \"id\": self.docs[doc_id]['id']\n",
        "            }\n",
        "        )\n",
        "\n",
        "    sources_retrieved = []\n",
        "\n",
        "    for docs_retrieved_item in docs_retrieved:\n",
        "      sources_retrieved.append(self.sources[docs_retrieved_item['id']])\n",
        "\n",
        "    return sources_retrieved, docs_retrieved"
      ],
      "metadata": {
        "id": "PytcPApKnz2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SearchEngine:\n",
        "  def __init__(self, docs: Documents):\n",
        "    self.documents = documents\n",
        "    self.conversation_id = str(uuid.uuid4())\n",
        "\n",
        "  def retrieve_and_summarize(self, profile_index: int):\n",
        "\n",
        "    summarized_profile = co.summarize(preprocess(profiles[profile_index]))\n",
        "\n",
        "    sources, docs = self.retrieve_sources(summarized_profile)\n",
        "\n",
        "    summarized_docs = []\n",
        "    for doc in docs:\n",
        "      summarized_docs.append({ \"text\": co.summarize(doc['text']), \"id\": doc[\"id\"]})\n",
        "\n",
        "    result = []\n",
        "\n",
        "    for index, summarized_doc in enumerate(summarized_docs):\n",
        "      response_why = co.chat(\n",
        "          message=f\"Can you explain why the following profile: {summarized_doc['text']}, is a good match for this profile: {summarized_profile}, as co-founder?\",\n",
        "          model=\"command\",\n",
        "\t        temperature=0.9\n",
        "      )\n",
        "      name_key = [item for item in sources[index].keys() if item not in ['profile_url', 'background', 'experience', 'education', 'skills']]\n",
        "      print(f\"Matched {index + 1} People...\")\n",
        "      result.append({\n",
        "          \"name\": sources[index][name_key[0]],\n",
        "          \"title\": \"\",\n",
        "          \"summary_of_matches\": response_why.text\n",
        "      })\n",
        "\n",
        "    return { \"matches\": result }\n",
        "\n",
        "  def retrieve_sources(self, summarized_profile: str):\n",
        "    sources, docs = self.documents.retrieve(f\"Find a co-founder with complementary skillset given the following profile?: {summarized_profile}\")\n",
        "    return sources, docs"
      ],
      "metadata": {
        "id": "RAz63szwMuIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = Documents(profiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r5235e9SqCF",
        "outputId": "f2d08976-713c-48d2-9ae4-0a5df08366e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding documents...\n",
            "Indexing documents...\n",
            "Indexing complete with 75 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_engine = SearchEngine(documents)"
      ],
      "metadata": {
        "id": "PmNxzj3ZMvi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = search_engine.retrieve_and_summarize(2)"
      ],
      "metadata": {
        "id": "jv4MyOu2QTQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccMRD3Q0TChC",
        "outputId": "9965bbe0-964b-4cf8-9828-15515ab9fd7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matches': [{'name': 'Sophia Patel',\n",
              "   'title': '',\n",
              "   'summary_of_matches': \"Sophia and Daniel appear to have similar profiles as entrepreneurs with technical backgrounds in healthcare technology. However, the key difference lies in their specific roles, expertise, and the focus of their respective companies.\\n\\nSophia Patel's background summarizes her as a Co-Founder and CEO of HealthTech Innovations, indicating her leadership position and the company's mission to improve healthcare access through telemedicine and remote monitoring solutions. Her background in both medicine and computer science makes her well-suited to drive innovation in healthcare technology.\\n\\nOn the other hand, Daniel Kim's background summarizes him as the Founder and CEO of HealthAI Innovations, emphasizing his expertise in artificial intelligence and machine learning as well as his ability to found and grow startups in this domain. His background in electrical engineering and computer science, coupled with his experience as a CTO at TechMind AI, demonstrates his technical prowess in the field of AI and its applications in healthcare technology.\\n\\nBased on this information, Daniel Kim would be a better match for a co-founder position in a startup, considering his specialized experience in founding and growing AI-focused startups, which is not explicitly highlighted in Sophia Patel's profile. \\n\\nWould you like me to generate a summary for any other profiles you have in mind?\"},\n",
              "  {'name': 'Alexandra Turner',\n",
              "   'title': '',\n",
              "   'summary_of_matches': \"Based on the information provided about both individuals, it seems that Alexandra Turner and Daniel Kim might be a good match to potentially co-found a company together. Both of them possess impressive backgrounds in entrepreneurship and have started multiple companies in the past, namely GenoHealth Sciences and HealthAI Innovations for Turner, and TechMind AI and HealthAI Innovations for Kim. \\n\\nTurner and Kim also appear to have complementary skill sets, which could be beneficial for a co-founder relationship. Turner's specialties include biotechnology, startup leadership, fundraising, and team building, whereas Kim's expertise lies in founding startups leveraging AI and machine learning, as well as in the healthcare technology sector. \\n\\nIt's worth noting that there may be other important factors to consider when choosing a co-founder, such as shared values, complementary working styles, and chemistry between the individuals. Nonetheless, based on the provided summaries, Turner and Kim have backgrounds that suggest they could be a good fit for a co-founding team. \\n\\nWould you like me to generate more suggestions for a potential co-founding team based on the profiles you have provided?\"},\n",
              "  {'name': 'Emily Patel',\n",
              "   'title': '',\n",
              "   'summary_of_matches': 'Given the profiles of Emily Patel and Daniel Kim, it seems that Emily and Daniel could potentially make a good co-founding team due to their overlapping expertise and experience in the tech space, as well as their complementary skill sets.\\n\\nEmily Patel has over 10 years of experience in founding and leading startups in the tech and fashion industries, with a focus on creative direction, design, and branding. Her background in fashion design and business administration demonstrates a strong blend of creative and business skills, which could be advantageous in building a tech startup.\\n\\nDaniel Kim, on the other hand, has extensive experience in founding and growing startups that utilize AI and machine learning, particularly in the healthcare technology sector. His background in electrical engineering and computer science, coupled with his expertise in healthcare technology, predictive analytics, and data science, suggests that he could bring valuable technical and strategic expertise to a founding team.\\n\\nWhile Emily and Daniel have different backgrounds and areas of expertise, they both possess essential skills and experience relevant to building technology startups. Their combined knowledge of technology, entrepreneurship, and various industries could enable them to collaborate effectively and cover key aspects of founding and growing a successful business.\\n\\nIt is important to note that founding a company is a complex endeavor that requires alignment on goals, work style, and values. Although their profiles indicate complementary skills, it is recommended that they further discuss and assess their mutual compatibility and shared vision before making any formal decisions. \\n\\nWould you like me to help you summarize any other profiles?'},\n",
              "  {'name': 'John Nguyen',\n",
              "   'title': '',\n",
              "   'summary_of_matches': 'Given the information provided in both summaries, it seems that John Nguyen and Daniel Kim have similar backgrounds and expertise, making them potentially good candidates to co-found a company together. Here are some key similarities between the two:\\n\\nBoth Nguyen and Kim have extensive experience as founders and leaders in the artificial intelligence and robotics industries, with a track record of developing innovative solutions and driving growth in these sectors.\\n\\nThey both possess strong technical backgrounds, with Masters degrees in Computer Science and related fields, as well as expertise in areas such as artificial intelligence, machine learning, startup founding, technology leadership, and product development.\\n\\nThey have worked in similar roles and held similar positions in their respective companies, including founding and serving as CEO or CTO.\\n\\nThey both appear to have successful careers in founding and growing startups in the AI and machine learning space.\\n\\nWith their shared technical expertise and entrepreneurial acumen, Nguyen and Kim would likely be able to complement each other well as co-founders. However, there are always potential benefits and challenges to any collaboration, and it would be important to consider other factors beyond just shared skills and experience when choosing a co-founder. \\n\\nWould you like me to elaborate on any of the similarities between Nguyen and Kim, or provide additional insights regarding collaboration between co-founders?'},\n",
              "  {'name': 'Michael Chang',\n",
              "   'title': '',\n",
              "   'summary_of_matches': \"Given that both Michael Chang and Daniel Kim appear to be highly accomplished and experienced entrepreneurs with backgrounds in computer science and engineering, they could potentially make great co-founders. However, the key determinant of whether they would make good co-founders for a specific venture depends on the nature of the startup and the dynamic you aim to establish among the founding team.\\n\\nHere are a few factors to consider:\\n\\n1. Domain Alignment: Ensure that there is alignment in their respective areas of expertise and interest. If you are looking to build a fintech startup similar to FinTech Innovators, Michael Chang's experience in financial technology and banking could be highly relevant. If you are aiming to build a healthcare tech company like HealthAI Innovations, Daniel Kim's experience in healthcare technology and AI would be an excellent fit.\\n\\n2. Core Competencies and Skill Sets: Examine the complementary skills that each individual brings to the table. While both Chang and Kim have strong technical backgrounds, consider the specific technical competencies they possess. For example, if your startup requires strong leadership in technology and innovation, Chang's experience as a founder and CEO of multiple tech startups could be advantageous. If you value expertise in AI and machine learning, Kim's background in those fields could be a great fit.\\n\\n3. Working Style and Cultural Fit: Co-founding a company often involves navigating challenges and making important decisions together. It's crucial to ensure that your potential co-founders share similar values and work ethic. Consider whether Chang and Kim's backgrounds and approaches align with your vision for the culture and working dynamics of your startup.\\n\\n4. Chemistry and Mutual Respect: Ultimately, it's important to gauge the personal chemistry and mutual respect between you and any potential co-founder. Starting and running a company can be arduous, so ensure you are confident in your ability to work well together and be responsive to one another's needs.\\n\\nWhile the provided information offers insights into the experience and expertise of Michael Chang and Daniel Kim, the final determination of whether they would make suitable co-founders should involve in-depth discussions, the exploration of shared visions and goals, and consideration of various factors specific to your startup idea. \\n\\nWould you like me to help you assess any other aspects regarding the potential collaboration between Michael Chang and Daniel Kim as co-founders?\"}]}"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    }
  ]
}